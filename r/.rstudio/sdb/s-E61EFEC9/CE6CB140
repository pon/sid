{
    "collab_server" : "",
    "contents" : "# logistic_adaptive. theta=[.35,.45,.15], theta_hat={1,.1,2}\n\nlibrary(expm) # used, e.g. for sqrtm\n\nnmax1=15000\nxdim = 3\nxmin = c(350/100,20000/10000,250/100)\nxmu =  c(500/100,40000/10000,750/100)\n\nxstd = c(.4,.4,.4)\ntheta = c(.25,.25,.25)\ntheta_hat = c(.1,.1,.1)\n\nlast_theta = vector(\"numeric\",xdim)\nsumterm = vector(\"numeric\",xdim)\nx = matrix(0,nrow=nmax1,ncol=xdim)\ncorr = matrix(0,nrow=xdim,ncol=xdim)\ncorrsr = matrix(0,nrow=xdim,ncol=xdim)\nv = c(rep(0,xdim))\nw = c(rep(0,xdim))\nxtemp = c(rep(0,xdim))\nlambda = c(rep(0,nmax1))\nlambda0 = c(rep(0,nmax1))\nlambda1 = c(rep(0,nmax1))\ny = c(rep(0,nmax1))\n\nalpha = .005\ncorr[1,2]=.6\ncorr[1,3]=.5\ncorr[2,3]=.7\nfor (i in 1:xdim) {\n  corr[i,i] = 1\n  for (j in 1:xdim) {\n    corr[i,j] - corr[j,i]\n  }\n}\ncorrsr = sqrtm(corr)\n\n#************************************************************\n# Section 1: Generate sample training set.\n# x[i,j]=jth attribute of ith observation\n# lambda(i)=logist response to x[i,:], viewed as \"score\" \n# y[i]=:1 if rpois(lambda(i)) > 0\n# indk/nmax = Prob{simulated y = k}, k={0,1}, ind0+ind1=nmax\n# mean(lambda1[1:ind1])=ave \"score\" of defaulted vectors\n# mean(lambda0[1:ind0])=ave \"score\" of non-defaulted vectors\n\nind0=0\nind1=0\n# Generate Sample Training Set\n\ni=0\nwhile( i < nmax1) {\n  for (j in 1:xdim) {\n    v[j]=rnorm(1)\n  }\n  w = (corrsr %*% v)\n  \n  bad=0\n  htheta_sim=0\n  for (j in 1:xdim) {\n    xtemp[j] = (xstd[j]*w[j] + 1 )*xmu[j]            \n    if ( xtemp[j] < 0) {bad=1}                       \n  }\n  if (bad==0) {\n    i=i+1\n    for (j in 1:xdim) {\n      x[i,j] = xtemp[j]\n      htheta_sim = htheta_sim + xtemp[j]*theta[j]    \n    }\n    lambda[i] = 2 - (2/(1 + exp(-1*htheta_sim)) )    \n  }                                                  \n} \n\nnmax=i\nfor (i in 1:nmax) {\n  df = rpois(1,lambda[i])\n  if (df>0) {\n    y[i]=1\n    ind1=ind1+1\n    lambda1[ind1]=lambda[i]\n  }\n  else {\n    y[i]=0\n    ind0=ind0+1\n    lambda0[ind0]=lambda[i]\n  }\n}\n\n#***********************************************************\n# Begin training vis SGM\n# htheta = logist response (given theta_hat) to training vector\n# update theta_hat until training set exhausted\n# err1 and err2 measure CONVERGENCE performance\n\nerr2 = c(rep(0,xdim))\nerr1 = 0\n# count=0\n\nfor (i in 1:nmax) {\n  last_theta = theta_hat\n  htheta = 0\n  for (j in 1:xdim) {\n    htheta = htheta + theta_hat[j]*x[i,j]\n  }\n  htheta = 2 - ( 2/(1 + exp(-1*htheta)) )\n  tempvar = (htheta*(2 - htheta))/(1-htheta)\n  \n  for (j in 1:xdim) {\n    sumterm[j] = (tempvar - y[i]*(2-htheta + tempvar) ) * x[i,j]*0.5\n    theta_hat[j] = theta_hat[j] + alpha * sumterm[j]\n  }\n  err2 = theta_hat - last_theta\n  err1 = sqrt(err2[1]^2 + err2[2]^2 + err2[3]^2 )\n}\n\n#***************************************************************\n# Compute error between estimator yhat and test data ytest\n# 1) Generate test vector xtest[i,j], logist resp lambdatest(xtest,theta)\n#    generate test target: ytest[i]=1 if rpois(lambdatest) > 0\n# 2) Generate estimator yhat as follows: yhat[i]=logist_resp(xtest,theta_hat)\n# Then quantize yhat to {0,1}: yhat=: indicator { yhat[i] > threshold }\n# NOTE: Reject if yhat=1. If ytest=0 then FN (rejected good)\n#       Accept if yhat=0. If ytest=1 then FP (accepted bad)\n# estat = rms of ytest vs. yhat (BOTH BINARY). Also, rms_fp, rms_fn\n# estat_lambda = rms of logistic responses. lambdatest vs. yhat (before quantizing) \n\n\nxtest = matrix(0,nrow=nmax1,ncol=xdim)\nlambdatest = c(rep(0,nmax1))\nytest = c(rep(0,nmax1))\nyhat = c(rep(0,nmax1))\nestat = c(rep(0,xdim))\nestat_lambda = c(rep(0,xdim))\n\nthreshold=0.07\ni=0\nwhile ( i < nmax1) {\n  for (j in 1:xdim) {\n    v[j]=rnorm(1)\n  }\n  w = (corrsr %*% v)\n  \n  bad=0\n  htheta_test=0\n  htheta_hat=0\n  for (j in 1:xdim) {\n    xtemp[j] = (xstd[j]*w[j] + 1 )*xmu[j]            \n    if ( xtemp[j] < 0) {bad=1}                       \n  }\n  if (bad==0) {\n    i=i+1\n    for (j in 1:xdim) {\n      xtest[i,j] = xtemp[j]\n      htheta_test = htheta_test + xtemp[j]*theta[j] \n      htheta_hat = htheta_hat + xtemp[j]*theta_hat[j]\n    }\n    lambdatest[i] = 2 - (2/(1 + exp(-1*htheta_test)) )\n    yhat[i] = 2 - (2/(1 + exp(-1*htheta_hat)) )\n  }\n}  \n\nnmax=i\nrms_fp=0\nrms_fn=0\nrms=0\nrms_lambda=0\nrms_lambda_fp = 0\nrms_lambda_fn = 0\nrejcount=0\n\nfor (i in 1:nmax) {\n  df = rpois(1,lambdatest[i])\n  if (df>0) {\n    ytest[i]=1\n  }\n  else {\n    ytest[i]=0\n  }\n  rms_lambda = rms_lambda + (lambdatest[i]-yhat[i])^2\n  if (yhat[i]>threshold) {\n    rms_lambda_fn = rms_lambda_fn + (lambdatest[i]-yhat[i])^2\n    yhat[i]=1\n    rms_fn = rms_fn + ( ytest[i] - yhat[i] )^2\n    rejcount=rejcount+1\n  }\n  else {\n    rms_lambda_fp = rms_lambda_fp + (lambdatest[i]-yhat[i])^2\n    yhat[i]=0\n    rms_fp = rms_fp + ( ytest[i] - yhat[i] )^2\n  }\n  rms = rms + ( ytest[i] - yhat[i] )^2\n}\n\nestat[1] = rms/nmax\nestat[2] = rms_fn/rejcount\nestat[3] = rms_fp/(nmax-rejcount)\nestat_lambda[1] = rms_lambda/nmax\nestat_lambda[2] = rms_lambda_fn/rejcount\nestat_lambda[3] = rms_lambda_fp/(nmax-rejcount)\n\n",
    "created" : 1503357527899.000,
    "dirty" : false,
    "encoding" : "",
    "folds" : "",
    "hash" : "1092899422",
    "id" : "CE6CB140",
    "lastKnownWriteTime" : 1503357573,
    "last_content_update" : 1503357573082,
    "path" : "~/logistic.r",
    "project_path" : null,
    "properties" : {
        "tempName" : "Untitled1"
    },
    "relative_order" : 1,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_source"
}